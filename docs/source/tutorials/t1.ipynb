{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this when using colab. \n",
    "#%pip install pygeoinf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9645d",
   "metadata": {},
   "source": [
    "# Tutorial 1 - A first example\n",
    "\n",
    "The aim of this tutorial is to show how this package can be used to solve a simple, but non-trivial, linear inverse problem. The methods are not fully explained, with later tutorials gradually building up the various ideas. \n",
    "\n",
    "The problem is as follows. We consider a function, $u$, defined on the unit circle, $\\mathbb{S}^{1}$. We are given $n$ data of the form\n",
    "$$\n",
    "v_{i} = u(\\theta_{i}) + z_{i}, \n",
    "$$\n",
    "where the $\\theta_{i}$ are known points and the $z_{i}$ are normally distributed random errors. From this data, we wish to estimate the unknown function, $u$, as best as possible. \n",
    "\n",
    "To proceed, we shall suppose that $u$ is an element of the Sobolev space, $H^{s}(\\mathbb{S}^{1})$, with order $s>1/2$. It can be shown that on this space the the inverse problem is well-defined and that it can be solved using a range of methods that admit convergent numerical discretisations. \n",
    "\n",
    "First, we set up the model space, the forward operator, and a data error measure. With these terms defined, we can then define our forward problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2112f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pygeoinf as inf\n",
    "from pygeoinf.symmetric_space.circle import Sobolev\n",
    "\n",
    "\n",
    "# Set up the model space.\n",
    "model_space = Sobolev.from_sobolev_parameters(2, 0.05)\n",
    "\n",
    "\n",
    "# Set the sample points randomly.\n",
    "n = 20\n",
    "observation_points = model_space.random_points(n)\n",
    "\n",
    "# Set the forward operator using a method of the Sobolev class.\n",
    "forward_operator = model_space.point_evaluation_operator(observation_points)\n",
    "data_space = forward_operator.codomain\n",
    "\n",
    "# Set the data error measure. If standard deviation is zero, the data is  \n",
    "# free of observational errors. \n",
    "standard_deviation = 0.1\n",
    "data_error_measure = inf.GaussianMeasure.from_standard_deviation(\n",
    "    data_space, standard_deviation) if standard_deviation > 0 else None\n",
    "\n",
    "# Set up the forward problem\n",
    "forward_problem = inf.LinearForwardProblem(forward_operator, data_error_measure=data_error_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa6e62",
   "metadata": {},
   "source": [
    "With the forward problem set up, we can now generate synthetic data for a given model. To do this, we introduce a Gaussian measure on the model space from which a sample can be drawn. This prior measure will later be used within a Bayesian inversion, but for the moment it is just a convenient way to generate data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0968abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prior measure on the model space.\n",
    "model_prior_measure = model_space.heat_gaussian_measure(0.1, 1)\n",
    "\n",
    "# Sample a model and corresponding data.\n",
    "model, data = forward_problem.synthetic_model_and_data(model_prior_measure)\n",
    "\n",
    "# Plot the function along with the corresponding data.\n",
    "fig, ax = model_space.plot(model, color=\"k\", figsize=(15, 10))\n",
    "ax.errorbar(observation_points, data, 2 * standard_deviation, fmt=\"ko\", capsize=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b51289b",
   "metadata": {},
   "source": [
    "In our first approach to solving the inverse problem, we obtain the **minimum norm solution**. Of all the models that fit the data acceptably, this is the unique element with the smallest norm. This method yields a single prefered model and does not readily provide for a quantification of uncertainty. Note that it is possible for this method to fail. This occurs when there is no element of the model space that fits the data statistically. This occurrence should be rare, but it is possible within this randomised example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the inversion method. \n",
    "minimum_norm_inversion = inf.LinearMinimumNormInversion(forward_problem)\n",
    "\n",
    "# Get the operator that maps the data to the minimum norm solution. \n",
    "minimum_norm_operator = minimum_norm_inversion.minimum_norm_operator(inf.CGSolver(rtol=1e-8))\n",
    "\n",
    "# Compute and plot the minimum norm solution\n",
    "minimum_norm_model = minimum_norm_operator(data)\n",
    "\n",
    "fig, ax = model_space.plot(model, color='k', figsize=(15,10))\n",
    "model_space.plot(minimum_norm_model, fig=fig, ax=ax,  color='b')\n",
    "ax.errorbar(observation_points, data, 2 * standard_deviation, fmt=\"ko\", capsize=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dae9f7",
   "metadata": {},
   "source": [
    "For the second method, we perform a Bayesian inversion. This requires a prior measure to be defined on the model space, and for simplicity we use the one introduced earlier and from which our data has been generated. This method yields a posterior measure on the model space that is also Gaussian. The posterior expectation is computed directly, but the posterior covariance is returned as a lazyily-evaluated linear operator. This means that its action on any model vector can be computed on demand, but its matrix representation has not been determined and stored. To obtain an estimate of the model uncertainty, we form a low-rank approximation to the posterior covariance and sample from this to estimate point-wise standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b96fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the inversion method.\n",
    "bayesian_inversion = inf.LinearBayesianInversion(forward_problem, model_prior_measure)\n",
    "\n",
    "# Get the posterior distribiution.\n",
    "model_posterior_measure = bayesian_inversion.model_posterior_measure(\n",
    "    data, inf.CholeskySolver()\n",
    ")\n",
    "\n",
    "# Estimate the pointwise variance\n",
    "low_rank_posterior_approximation = model_posterior_measure.low_rank_approximation(\n",
    "    10, method=\"variable\", rtol=1e-4\n",
    ")\n",
    "model_pointwise_variance = low_rank_posterior_approximation.sample_pointwise_variance(100)\n",
    "model_pointwise_std = np.sqrt(model_pointwise_variance)\n",
    "\n",
    "\n",
    "# Plot the\n",
    "fig, ax = model_space.plot(model, color=\"k\", figsize=(15,10))\n",
    "ax.errorbar(observation_points, data, 2 * standard_deviation, fmt=\"ko\", capsize=2)\n",
    "model_space.plot(\n",
    "    model_posterior_measure.expectation, fig=fig, ax=ax, color=\"b\"\n",
    ")\n",
    "model_space.plot_error_bounds(\n",
    "    model_posterior_measure.expectation,\n",
    "    2 * model_pointwise_std,\n",
    "    fig=fig,\n",
    "    ax=ax,\n",
    "    alpha=0.2,\n",
    "    color=\"b\",\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygeoinf-0ZCu7S8P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
