{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this when using colab. \n",
    "#%pip install pygeoinf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb2eb9",
   "metadata": {},
   "source": [
    "# Tutorial 5 - Gaussian measures\n",
    "\n",
    "A Gaussian measure on a Hilbert space, $X$, generalises the familar Gaussian distribution on finite-dimensionsl Euclidean spaces. Such a measure, $\\mu$, is characterised by its **expectation**, this being an element of $X$, and its **covariance** which is a self-adjoint and trace-class linear operator on $X$. We use the notation $\\mathcal{N}_{X}(\\overline{u}, Q)$ to denote a Gaussian measure on $X$ with expectation $\\overline{u} \\in X$ and covariance $Q \\in \\mathrm{Hom}(X)$. If an $X$-valued random variable has probability law $\\mu$ then we write $u \\sim \\mu$. Note that within this discussion the terms \"probability measure\" and \"probability distribition\" are used interchangably, with the prefix \"probability\" typically being dropped. \n",
    "\n",
    "Within ```pygeoinf``` Gaussian measures are implemented withint the ```GaussianMeasure``` class. This class stores the measure's expectation and covariance while also providing a range of useful methods.\n",
    "\n",
    "### Constructing a Gaussian measure\n",
    "\n",
    "A instance of ```GaussianMeasure``` can be constructed by provide either of the following keyword arguments: \n",
    "\n",
    "- ```covariance```: The covariance, $Q$, as an instance of ```LinearOperator```. \n",
    "- ```covariance_factor```:  A Cholesky factor, $L$, for the covariance such that $Q = LL^{*}$. The factor $L$ is given as a ```LinearOperator``` from a Euclidean space into the domain of the measure. \n",
    "\n",
    "A range of other keyword arguments can be provided:\n",
    "\n",
    "- ```expectation```: The expected value for the measure. The default is ```None``` in which case the measure has zero expectation. \n",
    "- ```sample```: A callable object that takes no arguments and returns sample from the measure. The default is ```None```. \n",
    "- ```inverse_covariance```: The inverse of the covariance as a ```LinearOperator```. The default is ```None```.\n",
    "- ```inverse_covariance_factor```: The inverse of the covariance factor. The default is ```None```. \n",
    "\n",
    "If the covariance factor, $L \\in \\mathrm{Hom}(\\mathbb{R}^{n},X)$, samples from the measure can be efficiently generated in the form\n",
    "$$\n",
    "u = \\overline{u} + L w, \n",
    "$$\n",
    "where $w \\sim \\mathcal{N}_{\\mathbb{R}^{n}}(0, \\mathrm{Id}_{\\mathbb{R}^{n}})$. This approach takes precedence over any user provided sampling method. \n",
    "\n",
    "As a first example, we construct a ```GaussianMeasure``` defined on ```EuclideanSpace``` by setting its covariance and expectation. Because no ```sample``` method has been provided, it is not possible to generate samples from the measure. Note that in constructing the covariance we first set it as a numpy matrix and then form a ```LinearOperator``` using the static method ```self_adjoint_from_matrix```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygeoinf as inf\n",
    "\n",
    "# Set the space. \n",
    "X = inf.EuclideanSpace(5)\n",
    "\n",
    "# Set the expectation\n",
    "expectation = np.random.randn(X.dim)\n",
    "\n",
    "# Generate a covariance matrix\n",
    "matrix = np.random.randn(X.dim, X.dim)\n",
    "covariance_matrix = matrix @ matrix.T\n",
    "covariance = inf.LinearOperator.self_adjoint_from_matrix(X, covariance_matrix)\n",
    "\n",
    "# Set the GaussianMeasure\n",
    "mu = inf.GaussianMeasure(covariance=covariance, expectation=expectation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990e62d",
   "metadata": {},
   "source": [
    "Such a ```GaussianMeasure``` has relatively little functionality. But its basic data can be accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'mu.domain == X is: {mu.domain == X}')\n",
    "print(f'Expectation of the measure: {mu.expectation}')\n",
    "print(f'Covariance of the measure:\\n {mu.covariance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e478229",
   "metadata": {},
   "source": [
    "Let's redefine this measure using the same expectation and covariance, but now providing a sampling method via ```scipy.stats```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af12448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import  multivariate_normal\n",
    "\n",
    "# Set up the scipy multivariate normal. \n",
    "distribution = multivariate_normal(mean = expectation, cov = covariance_matrix)\n",
    "\n",
    "# Now set the Gassian measure including a sampling method. \n",
    "mu = (inf.GaussianMeasure(\n",
    "        covariance=covariance,\n",
    "        expectation=expectation,\n",
    "        sample=lambda : distribution.rvs())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e2eccf",
   "metadata": {},
   "source": [
    "Using this new measure, we can generate random samples using ```sample``` for a single sample or ```samples``` for multiple samples returned as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a single sample. \n",
    "print(f'A sample from the measure:\\n {mu.sample()}')\n",
    "\n",
    "# Get a list of ten samples and print them\n",
    "print(f'A set of samples from the measure:')\n",
    "samples = mu.samples(10)\n",
    "for i, sample in enumerate(samples):\n",
    "    print(f'{sample}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331f4cd",
   "metadata": {},
   "source": [
    "A static method, ```from_covariance_matrix``` is provided that can simplify the construction of simple Gaussian measures. Internally, the eigen-decomposition of the covariance matrix is formed and used to factor both the covariance and inverse covariance. Note that the matrix input is the Galerkin representation of the covariance. Because this method is based on the storage and factorisation of dense matrices it is inefficient in high-dimensional spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34760947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form from using the static method.\n",
    "mu = inf.GaussianMeasure.from_covariance_matrix(X, covariance_matrix, expectation=expectation)\n",
    "\n",
    "print(f'Expectation of the measure: {mu.expectation}')\n",
    "print(f'Covariance of the measure:\\n {mu.covariance}')\n",
    "\n",
    "# The sampling method is now set for us. \n",
    "samples = mu.samples(10)\n",
    "for i, sample in enumerate(samples):\n",
    "    print(f'sample {i} is equal to: {sample}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184588d",
   "metadata": {},
   "source": [
    "### Other static methods for constructing Gaussian measures\n",
    "\n",
    "In addition to ```from_covariance_matrix``` a several other static methods are provided for constructing common Gaussian measures. In each case an efficient sampling method is provided. \n",
    "\n",
    "The method ```from_standard_deviation``` returns a Gaussian measure on $X$ whose covariance takes the form\n",
    "$$\n",
    "Q = \\sigma^{2}\\,\\mathrm{Id}_{X}, \n",
    "$$\n",
    "with $\\sigma$ the standard deviation and $\\mathrm{Id}_{X}$ the identity operator on $X$. Due to the trace-class condition, this measure is only well-defined on finite-dimensional spaces. The expectation of the measure can optionally be set, with the default being zero. \n",
    "\n",
    "A related method is ```from_standard_deviations```. In this casem it is assumed that the Galerkin representation of the covariance is diagonal and hence only its diagonal values need to be provided. Again a non-zero expectation can be optionally set. \n",
    "\n",
    "A final method to mention for the timebeing is ```from_samples```. In this case, the user provides the domain for the measure along with a collection of its elements, $\\{x_{i}\\}_{i=1}^{n}$ with $n >1$. A measure is then constructed whose expectation is equal to the **sample expectation**\n",
    "$$\n",
    "\\overline{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_{i}, \n",
    "$$\n",
    "and whose covariance is is equal to the **sample covariance**\n",
    "$$\n",
    "Q = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_{i}-\\overline{x})\\otimes (x_{i}-\\overline{x}), \n",
    "$$\n",
    "with $\\otimes$ denoting the tensor product. In this case, samples from the measure can be generated in the form\n",
    "$$\n",
    "x = \\overline{x} + \\frac{1}{\\sqrt{n-1}}\\sum_{i=1}^{n} w_{i} \\,(x_{i}-\\overline{x})\n",
    "$$\n",
    "where the $w_{i}\\in \\mathbb{R}$ are drawn from the standard Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae1773",
   "metadata": {},
   "source": [
    "### Transformations of Gaussian measures\n",
    "\n",
    "Gaussian measures can be transformed in various ways. In particular, the push-forward of a Gaussian measure under an affine mapping remains Gaussian. Let $\\mu = \\mathcal{N}_{X}(\\overline{u},Q)$ and consider the affine mapping\n",
    "$$\n",
    "f(v) = v_{0} + A u,\n",
    "$$\n",
    "for $A \\in \\mathrm{Hom}(X,Y)$. It can then be shown that \n",
    "$$\n",
    "f_{*}\\mu = \\mathcal{N}_{Y}(v_{0} + A \\overline{u}, AQA^{*}).\n",
    "$$\n",
    "This idea is implemented in ```GaussianMeasure``` through the ```affine_mapping``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601734ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the codomain of the transformation\n",
    "Y = inf.EuclideanSpace(3)\n",
    "\n",
    "# Set the translation\n",
    "y0 = Y.random()\n",
    "\n",
    "# Set the operator to be the projection from X to Y.\n",
    "A = inf.LinearOperator(X, Y, lambda x : x[:Y.dim])\n",
    "\n",
    "# Push forward the measure mu. \n",
    "nu = mu.affine_mapping(translation=y0, operator=A)\n",
    "\n",
    "\n",
    "# Print the mean and covariance.\n",
    "print(f'Expectation of the measure: {nu.expectation}')\n",
    "print(f'Covariance of the measure:\\n {nu.covariance}')\n",
    "\n",
    "# The new measure has a sampling method so long as the original does:\n",
    "samples = nu.samples(10)\n",
    "for i, sample in enumerate(samples):\n",
    "    print(f'sample {i} is equal to: {sample}')\n",
    "\n",
    "\n",
    "# If the original measure is in factored form, so is the new one. \n",
    "print(nu.covariance_factor_set)\n",
    "\n",
    "# But the inverse of the covariance is not set. \n",
    "print(nu.inverse_covariance_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96acfd21",
   "metadata": {},
   "source": [
    "As special cases of the affine transformation, other algebraic operations with measures can be performed. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30bca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = 2 * mu\n",
    "print(f'Expectation of the measure: {pi.expectation}')\n",
    "print(f'Covariance of the measure:\\n {pi.covariance}')\n",
    "\n",
    "xi = mu + pi\n",
    "print(f'Expectation of the measure: {pi.expectation}')\n",
    "print(f'Covariance of the measure:\\n {pi.covariance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcb999",
   "metadata": {},
   "source": [
    "### Gaussian measures on function spaces\n",
    "\n",
    "So far we have considered Gaussian measures defined on Euclidean spaces. But all the ideas carry over to function spaces. Looking, as usual, at the case of $H^{s}(\\mathbb{S}^{1})$ the class ```Sobolev``` in ```pygeoinf.symmetric_space.circle``` provides methods for generating a number of useful ```GaussianMeasures```. All these measures have in common invariance under the domains underlying symmetry group which, in this case, is $\\mathrm{SO}(1)$. It can be shown that the covariance for such a measure takes the form $f(\\Delta)$ with $f$ a function that decreases sufficient fast and $\\Delta$ the Laplacian. A method ```invariant_gaussian_measure``` is provided that can generate such a meaure given the function, $f$. This is then used to generate measures for two conventional choices of $f$. The first is ```sobolev_gaussian_measure``` whose covariance is given by \n",
    "$$\n",
    "Q = \\alpha (1 + \\lambda^{2}\\Delta)^{-s}, \n",
    "$$\n",
    "with $\\alpha$, $\\lambda$ and $s$ being parameters.  The second is ```heat_gaussian_measure``` whose covariance is given by \n",
    "$$\n",
    "Q = \\alpha \\mathrm{e}^{-\\lambda^{2}\\Delta}, \n",
    "$$\n",
    "with $\\alpha$ and $\\lambda$ being parameters. In either case the value of $\\alpha$ is implicitly set by specifying an ```amplitude``` which is equal to the pointwise standard deviation for random fields generated from the measure. \n",
    "\n",
    "In the code below we set up ```heat_gaussian_measure`` and plot a set of samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281bced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pygeoinf.symmetric_space.circle import Sobolev\n",
    "\n",
    "X = Sobolev.from_sobolev_parameters(2,0.01)\n",
    "\n",
    "u = X.project_function(lambda th : np.sin(th))\n",
    "\n",
    "mu = X.heat_gaussian_measure(0.05, 0.1, expectation=u)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "X.plot(mu.expectation, fig=fig, ax=ax, color = 'k')\n",
    "number_of_samples = 100\n",
    "samples = mu.samples(number_of_samples)\n",
    "for sample in samples:\n",
    "    X.plot(sample, fig=fig, ax=ax, color = 'k', alpha = 1/number_of_samples)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25921f0e",
   "metadata": {},
   "source": [
    "Just as in the finite-dimensional case, we can transform the measure under an affine mapping. Here we set up the derivative operator as in Tutorial 4 and use this to push forward our measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918abaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Sobolev.from_sobolev_parameters(1,0.01)\n",
    "\n",
    "# Define the derivative mapping\n",
    "def mapping(u):\n",
    "    coeff = X.to_coefficient(u)\n",
    "    for k in range(coeff.size):\n",
    "        coeff[k] *= 1j * k\n",
    "    return Y.from_coefficient(coeff)\n",
    "\n",
    "# Define the formal adjoint. Note that this\n",
    "# needs a separate definition because the two \n",
    "# spaces have different spatial discretisations. \n",
    "def formal_adjoint_mapping(v):\n",
    "    coeff = Y.to_coefficient(v)\n",
    "    for k in range(coeff.size):\n",
    "        coeff[k] *= -1j * k\n",
    "    return X.from_coefficient(coeff)\n",
    "\n",
    "    \n",
    "# Set up the operator. \n",
    "A = inf.LinearOperator(X, Y, mapping, formal_adjoint_mapping=formal_adjoint_mapping)\n",
    "\n",
    "nu = mu.affine_mapping(operator=A)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "Y.plot(nu.expectation, fig=fig, ax=ax, color = 'k')\n",
    "samples = nu.samples(number_of_samples)\n",
    "for sample in samples:\n",
    "    Y.plot(sample, fig=fig, ax=ax, color = 'k', alpha = 1/number_of_samples)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygeoinf-0ZCu7S8P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
