{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05028371",
   "metadata": {},
   "source": [
    "# Tutorial 8: A Deeper Look at Bayesian Inversion\n",
    "\n",
    "In this tutorial, we'll explore the `LinearBayesianInversion` class in more detail. We will see how it combines information from a **prior** and a **likelihood** to produce a **posterior** distribution that represents our updated state of knowledge.\n",
    "\n",
    "### The Bayesian Framework\n",
    "\n",
    "The goal of Bayesian inversion is to compute the posterior probability distribution $p(u|d)$ using Bayes' theorem:\n",
    "$$\n",
    "p(u|d) = \\frac{p(d|u) p(u)}{p(d)}\n",
    "$$\n",
    "* $p(u)$ is the **prior distribution**. This is a `GaussianMeasure` that encodes our knowledge about the model `u` *before* we see any data.\n",
    "* $p(d|u)$ is the **likelihood**. This is determined by the forward problem and our data error statistics. It tells us how likely it is to observe data `d` given a particular model `u`.\n",
    "* $p(u|d)$ is the **posterior distribution**. This is our updated `GaussianMeasure` for the model *after* observing the data. It combines the information from the prior and the likelihood.\n",
    "\n",
    "### Is Bayesian Inversion \"Better\"?\n",
    "\n",
    "Bayesian inversion is not inherently \"better\" than optimization methods; it is a different tool with different goals. Its main advantage is that it provides a full quantification of uncertainty. However, the result is only as good as the information you put in. A reasonable, well-justified **prior** is essential. A poor or incorrect prior can bias the result and lead to misleading conclusions.\n",
    "\n",
    "In this tutorial, we will:\n",
    "1.  Solve our circle inverse problem with a \"good\" prior.\n",
    "2.  Solve the same problem again with a deliberately \"wrong\" prior.\n",
    "3.  Compare the results to see the influence of the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run in colab, uncomment the line below to install pygeoinf. \n",
    "#%pip install pygeoinf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pygeoinf as inf\n",
    "from pygeoinf.symmetric_space.circle import Sobolev, CircleHelper\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8102b",
   "metadata": {},
   "source": [
    "## 1. Setting up the Problem\n",
    "\n",
    "First, let's set up the same inverse problem as before and generate our synthetic \"true\" model and data. The true model is generated from a prior with a characteristic length-scale of `0.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb2ef1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ce0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup the forward problem ---\n",
    "model_space = Sobolev.from_sobolev_parameters(2.0, 0.05)\n",
    "n_data = 20\n",
    "observation_points = model_space.random_points(n_data)\n",
    "forward_operator = model_space.point_evaluation_operator(observation_points)\n",
    "data_space = forward_operator.codomain\n",
    "standard_deviation = 0.1\n",
    "data_error_measure = inf.GaussianMeasure.from_standard_deviation(\n",
    "    data_space, standard_deviation\n",
    ")\n",
    "forward_problem = inf.LinearForwardProblem(\n",
    "    forward_operator, data_error_measure=data_error_measure\n",
    ")\n",
    "\n",
    "# --- Generate synthetic data from a \"true\" prior ---\n",
    "# This prior assumes the function has a relatively short correlation length (scale=0.1)\n",
    "true_prior = model_space.point_value_scaled_heat_kernel_gaussian_measure(\n",
    "    0.1, 1.0\n",
    ")\n",
    "true_model, data = forward_problem.synthetic_model_and_data(true_prior)\n",
    "\n",
    "print(\"Forward problem and synthetic data are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69101dc4",
   "metadata": {},
   "source": [
    "## 2. Inversion with a \"Good\" Prior\n",
    "\n",
    "First, we perform the Bayesian inversion using a prior that is consistent with the process that generated the true data. This represents a situation where we have good prior knowledge about the system we are modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a865d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prior is the same as the one used to generate the data\n",
    "good_prior = true_prior\n",
    "solver = inf.CholeskySolver(galerkin=True)\n",
    "\n",
    "# Set up and run the Bayesian inversion\n",
    "bayesian_inversion_good = inf.LinearBayesianInversion(forward_problem, good_prior)\n",
    "posterior_good = bayesian_inversion_good.model_posterior_measure(data, solver)\n",
    "posterior_mean_good = posterior_good.expectation\n",
    "\n",
    "# Estimate the pointwise uncertainty\n",
    "low_rank_good = posterior_good.low_rank_approximation(10, method=\"variable\", rtol = 1e-4)\n",
    "variance_good = low_rank_good.sample_pointwise_variance(200)\n",
    "std_dev_good = np.sqrt(variance_good)\n",
    "\n",
    "print(\"Inversion with 'good' prior is complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73491ad",
   "metadata": {},
   "source": [
    "## 3. Inversion with a \"Wrong\" Prior\n",
    "\n",
    "Now, let's see what happens if our prior information is misleading. We will define a new prior that assumes the function has a much **longer correlation length** (`scale=0.8`) than the true function. This represents a case where our initial assumptions about the system are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644618d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prior assumes the function is very smooth with a long correlation length\n",
    "wrong_prior = model_space.point_value_scaled_heat_kernel_gaussian_measure(\n",
    "    scale=0.8, amplitude=1.0\n",
    ")\n",
    "\n",
    "# Set up and run the Bayesian inversion with the wrong prior\n",
    "bayesian_inversion_wrong = inf.LinearBayesianInversion(forward_problem, wrong_prior)\n",
    "posterior_wrong = bayesian_inversion_wrong.model_posterior_measure(data, solver)\n",
    "posterior_mean_wrong = posterior_wrong.expectation\n",
    "\n",
    "# Estimate the pointwise uncertainty\n",
    "low_rank_wrong = posterior_wrong.low_rank_approximation(10, method=\"variable\", rtol=1e-4)\n",
    "variance_wrong = low_rank_wrong.sample_pointwise_variance(200)\n",
    "std_dev_wrong = np.sqrt(variance_wrong)\n",
    "\n",
    "print(\"Inversion with 'wrong' prior is complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c2dced",
   "metadata": {},
   "source": [
    "## 4. Comparing the Results\n",
    "\n",
    "Now, let's plot the results from both inversions side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "\n",
    "# --- Plot 1: Result with the Good Prior ---\n",
    "ax1.set_title(\"Result with a Good Prior (scale=0.1)\", fontsize=16)\n",
    "model_space.plot(true_model, fig=fig, ax=ax1, color=\"k\", linestyle=\"--\", label=\"True Model\")\n",
    "model_space.plot(posterior_mean_good, fig=fig, ax=ax1, color=\"b\", label=\"Posterior Mean\")\n",
    "model_space.plot_error_bounds(\n",
    "    posterior_mean_good, 2 * std_dev_good, fig=fig, ax=ax1, color=\"b\", alpha=0.2\n",
    ")\n",
    "ax1.errorbar(observation_points, data, 2 * standard_deviation, fmt=\"ko\", capsize=3, label=\"Data\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, linestyle=\":\")\n",
    "\n",
    "# --- Plot 2: Result with the Wrong Prior ---\n",
    "ax2.set_title(\"Result with a Wrong Prior (scale=0.8)\", fontsize=16)\n",
    "model_space.plot(true_model, fig=fig, ax=ax2, color=\"k\", linestyle=\"--\", label=\"True Model\")\n",
    "model_space.plot(posterior_mean_wrong, fig=fig, ax=ax2, color=\"r\", label=\"Posterior Mean\")\n",
    "model_space.plot_error_bounds(\n",
    "    posterior_mean_wrong, 2 * std_dev_wrong, fig=fig, ax=ax2, color=\"r\", alpha=0.2\n",
    ")\n",
    "ax2.errorbar(observation_points, data, 2 * standard_deviation, fmt=\"ko\", capsize=3, label=\"Data\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, linestyle=\":\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0254d56b",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The results are clear:\n",
    "* The inversion with the **good prior** produces a posterior that is close to the true model where the data is sufficient, and otherwise leads to realistically large uncertainties. \n",
    "* The inversion with the **wrong prior** produces a posterior mean that that is overly smooth though it does do a reasonable job of fitting the data. Crucially, however, the pointwise uncertainties are dramatically underestimated. \n",
    "\n",
    "This demonstrates the power and the main caveat of Bayesian methods: they provide a rigorous framework for combining prior knowledge with data, but the quality of the result depends directly on the quality of that prior knowledge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygeoinf-0ZCu7S8P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
