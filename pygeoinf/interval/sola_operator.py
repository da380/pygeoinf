"""
SOLA (Subtractive Optimally Localized Averages) operator implementation.

This module provides a LinearOperator that projects functions onto a set of
functions from any FunctionProvider using inner products, mapping from a
function space to a Euclidean space of coefficients.
"""

import numpy as np
from typing import Optional

from pygeoinf.hilbert_space import LinearOperator, EuclideanSpace
from pygeoinf.interval.function_providers import (
    FunctionProvider, IndexedFunctionProvider, NormalModesProvider
)


class SOLAOperator(LinearOperator):
    """
    SOLA operator that projects functions onto a FunctionProvider basis.

    This operator takes a function from an L2 space and computes inner products
    against functions generated by any FunctionProvider, resulting in a vector
    in the specified Euclidean space.

    The operator maps: L2Space -> EuclideanSpace
    """

    def __init__(self, domain, codomain: EuclideanSpace,
                 function_provider: Optional[FunctionProvider] = None,
                 random_state: Optional[int] = None,
                 cache_functions: bool = False):
        """
        Initialize the SOLA operator.

        Args:
            domain: L2Space instance (the function space)
            codomain: EuclideanSpace instance that defines the output dimension
            function_provider: Provider for generating projection functions.
                              If None, creates a default NormalModesProvider.
            random_state: Random seed for reproducible function generation
            cache_functions: If True, cache projection functions after first
                           access for faster repeated operations
        """
        self.N_d = codomain.dim
        self.cache_functions = cache_functions
        self._function_cache = {} if cache_functions else None

        # Create or use provided FunctionProvider
        if function_provider is None:
            self.function_provider = NormalModesProvider(
                domain,
                random_state=random_state,
                n_modes_range=(2, 5),
                coeff_range=(-1.0, 1.0),
                freq_range=(0.5, 5.0),
                gaussian_width_percent_range=(20.0, 40.0)
            )
        else:
            # Store the function provider for lazy evaluation
            self.function_provider = function_provider

        # Define the mapping function
        def mapping(func):
            """Project function onto the kernel basis."""
            return self._project_function(func)

        # Define the adjoint mapping
        def adjoint_mapping(data):
            """Reconstruct function from data."""
            return self._reconstruct_function(data)

        super().__init__(
            domain,
            codomain,
            mapping,
            adjoint_mapping=adjoint_mapping
        )

    def _get_projection_function(self, index: int):
        """
        Lazily get the i-th projection function with optional caching.

        Args:
            index: Index of the projection function to retrieve

        Returns:
            Function: The i-th projection function
        """
        # Check cache first if caching is enabled
        if self.cache_functions and index in self._function_cache:
            return self._function_cache[index]

        # Generate the function using the appropriate provider method
        if isinstance(self.function_provider, IndexedFunctionProvider):
            # Use the indexed access for providers that support it
            function = self.function_provider.get_function_by_index(index)
        else:
            # Fall back to sampling for providers that don't support indexing
            function = self.function_provider.sample_function()

        # Cache the function if caching is enabled
        if self.cache_functions:
            self._function_cache[index] = function

        return function

    def _project_function(self, func):
        """
        Project a function onto the kernels using lazy evaluation.

        Args:
            func: Function from the domain space

        Returns:
            numpy.ndarray: Vector of data in R^{N_d}
        """
        data = np.zeros(self.N_d)

        for i in range(self.N_d):
            # Lazily get the i-th projection function
            proj_func = self._get_projection_function(i)
            # Compute inner product with the i-th projection function
            data[i] = self.domain.inner_product(func, proj_func)

        return data

    def _reconstruct_function(self, data):
        """
        Reconstruct a function from data using lazy evaluation.

        Args:
            data: numpy.ndarray of data in R^{N_d}

        Returns:
            Function: Reconstructed function in the domain space
        """
        # Start with zero function
        reconstructed = self.domain.zero

        # Add weighted projection functions
        for i, coeff in enumerate(data):
            if abs(coeff) > 1e-14:  # Avoid numerical noise
                # Lazily get the i-th projection function
                proj_func = self._get_projection_function(i)
                reconstructed += coeff * proj_func

        return reconstructed

    def get_projection_functions(self):
        """
        Get the list of projection functions used by this operator.
        Note: This materializes all functions and may be expensive.

        Returns:
            list: List of projection functions used for projection
        """
        return [self._get_projection_function(i) for i in range(self.N_d)]

    def evaluate_projection_functions(self, x):
        """
        Evaluate all projection functions at given points using lazy
        evaluation.

        Args:
            x: numpy.ndarray of evaluation points

        Returns:
            numpy.ndarray: Matrix of shape (N_d, len(x)) with function values
        """
        values = np.zeros((self.N_d, len(x)))

        for i in range(self.N_d):
            proj_func = self._get_projection_function(i)
            values[i, :] = proj_func.evaluate(x)

        return values

    def compute_gram_matrix(self):
        """
        Compute the Gram matrix of the projection functions using lazy
        evaluation.

        Returns:
            numpy.ndarray: N_d x N_d matrix of inner products between
                          projection functions
        """
        gram = np.zeros((self.N_d, self.N_d))

        for i in range(self.N_d):
            proj_func_i = self._get_projection_function(i)
            for j in range(self.N_d):
                proj_func_j = self._get_projection_function(j)
                gram[i, j] = self.domain.inner_product(
                    proj_func_i, proj_func_j
                )

        return gram

    def clear_cache(self):
        """Clear the function cache if caching is enabled."""
        if self.cache_functions and self._function_cache:
            self._function_cache.clear()

    def get_cache_info(self):
        """
        Get information about the function cache.

        Returns:
            dict: Cache statistics including size and hit rate
        """
        if not self.cache_functions:
            return {"caching_enabled": False}

        return {
            "caching_enabled": True,
            "cached_functions": len(self._function_cache),
            "total_functions": self.N_d,
            "cache_coverage": len(self._function_cache) / self.N_d
        }

    def __str__(self):
        """String representation of the SOLA operator."""
        provider_type = type(self.function_provider).__name__
        return (f"SOLAOperator: {self.domain} -> {self.codomain}\n"
                f"  Uses {self.N_d} projection functions "
                f"from {provider_type}\n"
                f"  Domain dimension: {self.domain.dim}\n"
                f"  Codomain dimension: {self.codomain.dim}")
